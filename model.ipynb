{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import random\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
      "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
      "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
      "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
      "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
      "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
      "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
      "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
      "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
      "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
      "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
      "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
      "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
      "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
      "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
      "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
      "       'SaleCondition', 'SalePrice'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Process raw dataframe into one ready for a tensorflow tensor\n",
    "    '''\n",
    "    df.drop('Id', inplace=True, axis=1)\n",
    "    static_cols = df.columns\n",
    "    for c in static_cols:\n",
    "        if pd.api.types.is_numeric_dtype(df[c]):\n",
    "            fill_value = df[c].mean()\n",
    "            df[c] = df[c].fillna(fill_value)\n",
    "        elif pd.api.types.is_string_dtype(df[c]):\n",
    "            one_hot = pd.get_dummies(df[c], prefix=c)\n",
    "            df.drop(c, inplace=True, axis=1)\n",
    "            df = df.join(one_hot)\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError('Failed to find contained value of this column')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "train_data = preprocess(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 289 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          60         65.0     8450            7            5       2003   \n",
       "1          20         80.0     9600            6            8       1976   \n",
       "2          60         68.0    11250            7            5       2001   \n",
       "3          70         60.0     9550            7            5       1915   \n",
       "4          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  SaleType_ConLw  \\\n",
       "0          2003       196.0         706           0  ...               0   \n",
       "1          1976         0.0         978           0  ...               0   \n",
       "2          2002       162.0         486           0  ...               0   \n",
       "3          1970         0.0         216           0  ...               0   \n",
       "4          2000       350.0         655           0  ...               0   \n",
       "\n",
       "   SaleType_New  SaleType_Oth  SaleType_WD  SaleCondition_Abnorml  \\\n",
       "0             0             0            1                      0   \n",
       "1             0             0            1                      0   \n",
       "2             0             0            1                      0   \n",
       "3             0             0            1                      1   \n",
       "4             0             0            1                      0   \n",
       "\n",
       "   SaleCondition_AdjLand  SaleCondition_Alloca  SaleCondition_Family  \\\n",
       "0                      0                     0                     0   \n",
       "1                      0                     0                     0   \n",
       "2                      0                     0                     0   \n",
       "3                      0                     0                     0   \n",
       "4                      0                     0                     0   \n",
       "\n",
       "   SaleCondition_Normal  SaleCondition_Partial  \n",
       "0                     1                      0  \n",
       "1                     1                      0  \n",
       "2                     1                      0  \n",
       "3                     0                      0  \n",
       "4                     1                      0  \n",
       "\n",
       "[5 rows x 289 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_data = train_data[train_data.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(bad_data.shape[0] == 0) # catch bad preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to Tensorflow Dataset (and split validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_df_train = train_data['SalePrice']\n",
    "x_df_train = train_data.drop('SalePrice', inplace=False, axis=1)\n",
    "scaler = preprocessing.StandardScaler().fit(x_df_train)\n",
    "x_df_train = scaler.transform(x_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(x_df_train, y_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_val, y_train, y_val = tf.convert_to_tensor(X_train), tf.convert_to_tensor(X_val), tf.convert_to_tensor(y_train), tf.convert_to_tensor(y_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_non_seq_model():\n",
    "    input = tf.keras.Input(shape=[288,])\n",
    "    hidden1 = tf.keras.layers.Dense(300, activation='relu')(input)\n",
    "    hidden2 = tf.keras.layers.Dense(300, activation='relu')(hidden1)\n",
    "    hidden3 = tf.keras.layers.Dense(150, activation='relu')(hidden2)\n",
    "    hidden4 = tf.keras.layers.Dense(75, activation='relu')(hidden3)\n",
    "    concat = tf.keras.layers.Concatenate()([input, hidden4])\n",
    "    output = tf.keras.layers.Dense(1)(concat)\n",
    "    model = tf.keras.Model(inputs=[input], outputs=[output])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "loss_fn = MeanSquaredError()\n",
    "model = create_non_seq_model()\n",
    "model.compile(optimizer='adam', loss=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_14 (InputLayer)          [(None, 288)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 300)          86700       ['input_14[0][0]']               \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 300)          90300       ['dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 150)          45150       ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 75)           11325       ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 363)          0           ['input_14[0][0]',               \n",
      "                                                                  'dense_26[0][0]']               \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 1)            364         ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 233,839\n",
      "Trainable params: 233,839\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "110/110 [==============================] - 1s 2ms/step - loss: 30090582016.0000 - val_loss: 7743327232.0000\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 3080994560.0000 - val_loss: 3513700608.0000\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 1542386816.0000 - val_loss: 3154296576.0000\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 1089739904.0000 - val_loss: 2913876992.0000\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 812152064.0000 - val_loss: 2719566592.0000\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 623062016.0000 - val_loss: 2555188736.0000\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 491654528.0000 - val_loss: 2414596608.0000\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 398897216.0000 - val_loss: 2295939840.0000\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 333721952.0000 - val_loss: 2195287296.0000\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 286839488.0000 - val_loss: 2112099968.0000\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 251313856.0000 - val_loss: 2043669376.0000\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 224022416.0000 - val_loss: 1990305536.0000\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 202917056.0000 - val_loss: 1947518208.0000\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 185183696.0000 - val_loss: 1911889408.0000\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 170183792.0000 - val_loss: 1880194560.0000\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 157197312.0000 - val_loss: 1858485120.0000\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 145821504.0000 - val_loss: 1832512640.0000\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 135486208.0000 - val_loss: 1812364800.0000\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 126185408.0000 - val_loss: 1791082752.0000\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 117550024.0000 - val_loss: 1774954368.0000\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 110127336.0000 - val_loss: 1756186112.0000\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 103660816.0000 - val_loss: 1741270912.0000\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 98586096.0000 - val_loss: 1715807872.0000\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 93811832.0000 - val_loss: 1703026816.0000\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 89885952.0000 - val_loss: 1682621184.0000\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 87697872.0000 - val_loss: 1672391296.0000\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 85185080.0000 - val_loss: 1654146176.0000\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 83199040.0000 - val_loss: 1643451648.0000\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 81525384.0000 - val_loss: 1629131264.0000\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 82434136.0000 - val_loss: 1623603584.0000\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 80232800.0000 - val_loss: 1609822720.0000\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 80018624.0000 - val_loss: 1593674240.0000\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 77319592.0000 - val_loss: 1593226368.0000\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 78157808.0000 - val_loss: 1573255424.0000\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 73839024.0000 - val_loss: 1589067904.0000\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 69217488.0000 - val_loss: 1561937920.0000\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 66351436.0000 - val_loss: 1560626944.0000\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 68065400.0000 - val_loss: 1559508096.0000\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 68284528.0000 - val_loss: 1556699392.0000\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 60680120.0000 - val_loss: 1547611136.0000\n",
      "Epoch 41/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 56879988.0000 - val_loss: 1534492160.0000\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 52468980.0000 - val_loss: 1539376768.0000\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 52299040.0000 - val_loss: 1522176896.0000\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 52699800.0000 - val_loss: 1547866240.0000\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 52534080.0000 - val_loss: 1533667072.0000\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 53441292.0000 - val_loss: 1544819840.0000\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 55401920.0000 - val_loss: 1532670720.0000\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 63624832.0000 - val_loss: 1510575360.0000\n",
      "Epoch 49/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 66647664.0000 - val_loss: 1594032128.0000\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 59077560.0000 - val_loss: 1515254272.0000\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 49540772.0000 - val_loss: 1551636992.0000\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 40573888.0000 - val_loss: 1557554816.0000\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 37461324.0000 - val_loss: 1593390720.0000\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 35202900.0000 - val_loss: 1579844608.0000\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 42794464.0000 - val_loss: 1574009856.0000\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 44667012.0000 - val_loss: 1586120192.0000\n",
      "Epoch 57/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 55041724.0000 - val_loss: 1673888000.0000\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 60093964.0000 - val_loss: 1606782592.0000\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 65728996.0000 - val_loss: 1619411200.0000\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 66862528.0000 - val_loss: 1572673792.0000\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 60028120.0000 - val_loss: 1580349824.0000\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 44438944.0000 - val_loss: 1560825984.0000\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 36177628.0000 - val_loss: 1580191104.0000\n",
      "Epoch 64/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 39316388.0000 - val_loss: 1533529472.0000\n",
      "Epoch 65/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 50136656.0000 - val_loss: 1525379072.0000\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 59803200.0000 - val_loss: 1563799936.0000\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 100191360.0000 - val_loss: 1831338752.0000\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 154967376.0000 - val_loss: 2268266496.0000\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 227219568.0000 - val_loss: 1691021312.0000\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 169952512.0000 - val_loss: 1597890432.0000\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 107642264.0000 - val_loss: 1545039616.0000\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 75452424.0000 - val_loss: 1511878016.0000\n",
      "Epoch 73/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 69259368.0000 - val_loss: 1546012928.0000\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 69412312.0000 - val_loss: 1524227328.0000\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 72186712.0000 - val_loss: 1566344320.0000\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 72173120.0000 - val_loss: 1556278784.0000\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 72647408.0000 - val_loss: 1589780352.0000\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 71369480.0000 - val_loss: 1554615552.0000\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 74073944.0000 - val_loss: 1582044288.0000\n",
      "Epoch 80/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 71834528.0000 - val_loss: 1532895104.0000\n",
      "Epoch 81/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 76280288.0000 - val_loss: 1587068288.0000\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 71126616.0000 - val_loss: 1556588032.0000\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 76285168.0000 - val_loss: 1640082176.0000\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 72665520.0000 - val_loss: 1618525312.0000\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 78711112.0000 - val_loss: 1682402176.0000\n",
      "Epoch 86/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 83431536.0000 - val_loss: 1650994944.0000\n",
      "Epoch 87/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 89039968.0000 - val_loss: 1688840576.0000\n",
      "Epoch 88/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 97411432.0000 - val_loss: 1648625536.0000\n",
      "Epoch 89/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 108152224.0000 - val_loss: 1690670208.0000\n",
      "Epoch 90/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 117926472.0000 - val_loss: 1660351744.0000\n",
      "Epoch 91/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 147143136.0000 - val_loss: 1736813568.0000\n",
      "Epoch 92/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 180394272.0000 - val_loss: 1741303552.0000\n",
      "Epoch 93/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 241339984.0000 - val_loss: 1947356288.0000\n",
      "Epoch 94/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 316621408.0000 - val_loss: 2268079616.0000\n",
      "Epoch 95/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 371992192.0000 - val_loss: 2260920832.0000\n",
      "Epoch 96/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 327294304.0000 - val_loss: 1936022272.0000\n",
      "Epoch 97/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 229291376.0000 - val_loss: 1744512896.0000\n",
      "Epoch 98/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 152774800.0000 - val_loss: 1696990080.0000\n",
      "Epoch 99/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 92982248.0000 - val_loss: 1657108992.0000\n",
      "Epoch 100/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 66885404.0000 - val_loss: 1637348224.0000\n",
      "Epoch 101/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 43584376.0000 - val_loss: 1618976896.0000\n",
      "Epoch 102/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 34661080.0000 - val_loss: 1609006336.0000\n",
      "Epoch 103/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 25925872.0000 - val_loss: 1606950144.0000\n",
      "Epoch 104/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 23307242.0000 - val_loss: 1593418112.0000\n",
      "Epoch 105/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 20241782.0000 - val_loss: 1620348928.0000\n",
      "Epoch 106/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 21729410.0000 - val_loss: 1579368192.0000\n",
      "Epoch 107/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 21377618.0000 - val_loss: 1635893248.0000\n",
      "Epoch 108/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 24378888.0000 - val_loss: 1579417472.0000\n",
      "Epoch 109/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 21548634.0000 - val_loss: 1644413824.0000\n",
      "Epoch 110/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 22051596.0000 - val_loss: 1572054528.0000\n",
      "Epoch 111/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 21893842.0000 - val_loss: 1655820672.0000\n",
      "Epoch 112/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 21982550.0000 - val_loss: 1584448768.0000\n",
      "Epoch 113/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 20029224.0000 - val_loss: 1640021504.0000\n",
      "Epoch 114/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 19598600.0000 - val_loss: 1617704576.0000\n",
      "Epoch 115/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 19546346.0000 - val_loss: 1628160768.0000\n",
      "Epoch 116/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 20517830.0000 - val_loss: 1610776704.0000\n",
      "Epoch 117/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 21487428.0000 - val_loss: 1637185024.0000\n",
      "Epoch 118/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 21972862.0000 - val_loss: 1626667136.0000\n",
      "Epoch 119/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 20260546.0000 - val_loss: 1609745280.0000\n",
      "Epoch 120/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 20875896.0000 - val_loss: 1654090368.0000\n",
      "Epoch 121/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 25067934.0000 - val_loss: 1621936768.0000\n",
      "Epoch 122/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 31841634.0000 - val_loss: 1654722944.0000\n",
      "Epoch 123/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 37668228.0000 - val_loss: 1617667840.0000\n",
      "Epoch 124/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 39143004.0000 - val_loss: 1662877056.0000\n",
      "Epoch 125/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 31757624.0000 - val_loss: 1618295296.0000\n",
      "Epoch 126/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 27660064.0000 - val_loss: 1653848320.0000\n",
      "Epoch 127/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 23806650.0000 - val_loss: 1622407808.0000\n",
      "Epoch 128/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 22600008.0000 - val_loss: 1653798656.0000\n",
      "Epoch 129/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 22208480.0000 - val_loss: 1615344640.0000\n",
      "Epoch 130/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 23146914.0000 - val_loss: 1656736128.0000\n",
      "Epoch 131/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 28967090.0000 - val_loss: 1607947520.0000\n",
      "Epoch 132/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 31043254.0000 - val_loss: 1657662208.0000\n",
      "Epoch 133/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 30532948.0000 - val_loss: 1599423616.0000\n",
      "Epoch 134/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 30625462.0000 - val_loss: 1646299008.0000\n",
      "Epoch 135/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 36288092.0000 - val_loss: 1651560320.0000\n",
      "Epoch 136/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 44351832.0000 - val_loss: 1728021632.0000\n",
      "Epoch 137/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 82136784.0000 - val_loss: 1696930432.0000\n",
      "Epoch 138/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 162577728.0000 - val_loss: 1745307136.0000\n",
      "Epoch 139/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 182201168.0000 - val_loss: 1700355200.0000\n",
      "Epoch 140/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 128000400.0000 - val_loss: 1653905152.0000\n",
      "Epoch 141/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 54198508.0000 - val_loss: 1700508800.0000\n",
      "Epoch 142/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 32368268.0000 - val_loss: 1754414336.0000\n",
      "Epoch 143/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 27910662.0000 - val_loss: 1727765376.0000\n",
      "Epoch 144/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 29243894.0000 - val_loss: 1731848448.0000\n",
      "Epoch 145/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 26014548.0000 - val_loss: 1702631424.0000\n",
      "Epoch 146/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 31773906.0000 - val_loss: 1707812736.0000\n",
      "Epoch 147/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 27347846.0000 - val_loss: 1665861760.0000\n",
      "Epoch 148/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 32884058.0000 - val_loss: 1674137600.0000\n",
      "Epoch 149/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 29208042.0000 - val_loss: 1630825984.0000\n",
      "Epoch 150/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 34684148.0000 - val_loss: 1644000896.0000\n",
      "Epoch 151/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 32166104.0000 - val_loss: 1620812416.0000\n",
      "Epoch 152/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 35331828.0000 - val_loss: 1622679936.0000\n",
      "Epoch 153/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 38279700.0000 - val_loss: 1639186304.0000\n",
      "Epoch 154/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 39929452.0000 - val_loss: 1633673088.0000\n",
      "Epoch 155/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 46845908.0000 - val_loss: 1671071360.0000\n",
      "Epoch 156/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 48834296.0000 - val_loss: 1692574208.0000\n",
      "Epoch 157/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 63290720.0000 - val_loss: 1739019264.0000\n",
      "Epoch 158/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 72199448.0000 - val_loss: 1840395776.0000\n",
      "Epoch 159/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 99211752.0000 - val_loss: 1937980800.0000\n",
      "Epoch 160/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 136797088.0000 - val_loss: 2059550976.0000\n",
      "Epoch 161/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 215685680.0000 - val_loss: 1804468992.0000\n",
      "Epoch 162/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 247971024.0000 - val_loss: 1838778880.0000\n",
      "Epoch 163/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 185753536.0000 - val_loss: 1853257344.0000\n",
      "Epoch 164/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 171691504.0000 - val_loss: 1790524160.0000\n",
      "Epoch 165/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 140320896.0000 - val_loss: 1738680704.0000\n",
      "Epoch 166/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 120137696.0000 - val_loss: 1666977792.0000\n",
      "Epoch 167/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 103438208.0000 - val_loss: 1613975552.0000\n",
      "Epoch 168/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 88121968.0000 - val_loss: 1596379392.0000\n",
      "Epoch 169/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 75040792.0000 - val_loss: 1593340800.0000\n",
      "Epoch 170/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 65361356.0000 - val_loss: 1606457984.0000\n",
      "Epoch 171/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 53909376.0000 - val_loss: 1599591424.0000\n",
      "Epoch 172/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 50552400.0000 - val_loss: 1637831424.0000\n",
      "Epoch 173/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 40971744.0000 - val_loss: 1608101504.0000\n",
      "Epoch 174/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 36723508.0000 - val_loss: 1648785408.0000\n",
      "Epoch 175/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 31109306.0000 - val_loss: 1619788672.0000\n",
      "Epoch 176/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 30429978.0000 - val_loss: 1650641920.0000\n",
      "Epoch 177/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 31424146.0000 - val_loss: 1628244096.0000\n",
      "Epoch 178/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 28315904.0000 - val_loss: 1651120128.0000\n",
      "Epoch 179/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 24847236.0000 - val_loss: 1614750848.0000\n",
      "Epoch 180/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 22295144.0000 - val_loss: 1644337152.0000\n",
      "Epoch 181/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 19400574.0000 - val_loss: 1608299392.0000\n",
      "Epoch 182/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 21412034.0000 - val_loss: 1624197888.0000\n",
      "Epoch 183/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 20910200.0000 - val_loss: 1608431232.0000\n",
      "Epoch 184/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 21931646.0000 - val_loss: 1620268928.0000\n",
      "Epoch 185/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 23127922.0000 - val_loss: 1606895616.0000\n",
      "Epoch 186/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 23582456.0000 - val_loss: 1619490816.0000\n",
      "Epoch 187/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 25410786.0000 - val_loss: 1588239488.0000\n",
      "Epoch 188/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 27442196.0000 - val_loss: 1612638592.0000\n",
      "Epoch 189/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 28147354.0000 - val_loss: 1612498944.0000\n",
      "Epoch 190/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 29053626.0000 - val_loss: 1611787008.0000\n",
      "Epoch 191/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 32525052.0000 - val_loss: 1616893056.0000\n",
      "Epoch 192/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 32799054.0000 - val_loss: 1634105344.0000\n",
      "Epoch 193/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 36387612.0000 - val_loss: 1614807040.0000\n",
      "Epoch 194/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 35884976.0000 - val_loss: 1647022720.0000\n",
      "Epoch 195/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 37962800.0000 - val_loss: 1609640064.0000\n",
      "Epoch 196/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 44088684.0000 - val_loss: 1634533888.0000\n",
      "Epoch 197/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 45991056.0000 - val_loss: 1611195008.0000\n",
      "Epoch 198/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 65283948.0000 - val_loss: 1633577216.0000\n",
      "Epoch 199/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 68099696.0000 - val_loss: 1629258496.0000\n",
      "Epoch 200/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 83021520.0000 - val_loss: 1762971520.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20a508077f0>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, validation_data=val_ds, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('test.csv')\n",
    "test_set = preprocess(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 270)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7ac31377e5752e1ed1312ad3b91e8276a597b7c31b512ba5cfdf5263aeace113"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
