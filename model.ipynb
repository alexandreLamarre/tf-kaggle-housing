{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import random\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
      "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
      "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
      "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
      "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
      "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
      "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
      "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
      "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
      "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
      "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
      "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
      "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
      "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
      "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
      "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
      "       'SaleCondition', 'SalePrice'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Process raw dataframe into one ready for a tensorflow tensor\n",
    "    '''\n",
    "    df.drop('Id', inplace=True, axis=1)\n",
    "    static_cols = df.columns\n",
    "    for c in static_cols:\n",
    "        if pd.api.types.is_numeric_dtype(df[c]):\n",
    "            fill_value = df[c].mean()\n",
    "            df[c] = df[c].fillna(fill_value)\n",
    "        elif pd.api.types.is_string_dtype(df[c]):\n",
    "            one_hot = pd.get_dummies(df[c], prefix=c)\n",
    "            df.drop(c, inplace=True, axis=1)\n",
    "            df = df.join(one_hot)\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError('Failed to find contained value of this column')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "train_data = preprocess(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 289 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          60         65.0     8450            7            5       2003   \n",
       "1          20         80.0     9600            6            8       1976   \n",
       "2          60         68.0    11250            7            5       2001   \n",
       "3          70         60.0     9550            7            5       1915   \n",
       "4          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  SaleType_ConLw  \\\n",
       "0          2003       196.0         706           0  ...               0   \n",
       "1          1976         0.0         978           0  ...               0   \n",
       "2          2002       162.0         486           0  ...               0   \n",
       "3          1970         0.0         216           0  ...               0   \n",
       "4          2000       350.0         655           0  ...               0   \n",
       "\n",
       "   SaleType_New  SaleType_Oth  SaleType_WD  SaleCondition_Abnorml  \\\n",
       "0             0             0            1                      0   \n",
       "1             0             0            1                      0   \n",
       "2             0             0            1                      0   \n",
       "3             0             0            1                      1   \n",
       "4             0             0            1                      0   \n",
       "\n",
       "   SaleCondition_AdjLand  SaleCondition_Alloca  SaleCondition_Family  \\\n",
       "0                      0                     0                     0   \n",
       "1                      0                     0                     0   \n",
       "2                      0                     0                     0   \n",
       "3                      0                     0                     0   \n",
       "4                      0                     0                     0   \n",
       "\n",
       "   SaleCondition_Normal  SaleCondition_Partial  \n",
       "0                     1                      0  \n",
       "1                     1                      0  \n",
       "2                     1                      0  \n",
       "3                     0                      0  \n",
       "4                     1                      0  \n",
       "\n",
       "[5 rows x 289 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_data = train_data[train_data.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(bad_data.shape[0] == 0) # catch bad preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to Tensorflow Dataset (and split validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_df_train = train_data['SalePrice']\n",
    "x_df_train = train_data.drop('SalePrice', inplace=False, axis=1)\n",
    "scaler = preprocessing.StandardScaler().fit(x_df_train)\n",
    "x_df_train = scaler.transform(x_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(x_df_train, y_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_val, y_train, y_val = tf.convert_to_tensor(X_train), tf.convert_to_tensor(X_val), tf.convert_to_tensor(y_train), tf.convert_to_tensor(y_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_non_seq_model():\n",
    "    input = tf.keras.Input(shape=[288,])\n",
    "    hidden1 = tf.keras.layers.Dense(300, activation='relu')(input)\n",
    "    hidden2 = tf.keras.layers.Dense(300, activation='relu')(hidden1)\n",
    "    hidden3 = tf.keras.layers.Dense(300, activation='relu')(hidden2)\n",
    "    hidden4 = tf.keras.layers.Dense(300, activation='relu')(hidden3)\n",
    "    hidden5 = tf.keras.layers.Dense(150, activation='relu')(hidden4)\n",
    "    hidden6 = tf.keras.layers.Dense(75, activation='relu')(hidden5)\n",
    "    concat = tf.keras.layers.Concatenate()([input, hidden6])\n",
    "    output = tf.keras.layers.Dense(1)(concat)\n",
    "    model = tf.keras.Model(inputs=[input], outputs=[output])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "loss_fn = MeanSquaredError()\n",
    "model = create_non_seq_model()\n",
    "model.compile(optimizer='adam', loss=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_16 (InputLayer)          [(None, 288)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_33 (Dense)               (None, 300)          86700       ['input_16[0][0]']               \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 300)          90300       ['dense_33[0][0]']               \n",
      "                                                                                                  \n",
      " dense_35 (Dense)               (None, 300)          90300       ['dense_34[0][0]']               \n",
      "                                                                                                  \n",
      " dense_36 (Dense)               (None, 300)          90300       ['dense_35[0][0]']               \n",
      "                                                                                                  \n",
      " dense_37 (Dense)               (None, 150)          45150       ['dense_36[0][0]']               \n",
      "                                                                                                  \n",
      " dense_38 (Dense)               (None, 75)           11325       ['dense_37[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 363)          0           ['input_16[0][0]',               \n",
      "                                                                  'dense_38[0][0]']               \n",
      "                                                                                                  \n",
      " dense_39 (Dense)               (None, 1)            364         ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 414,439\n",
      "Trainable params: 414,439\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 63867512.0000 - val_loss: 3345975552.0000\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 48728540.0000 - val_loss: 3426696704.0000\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 35787548.0000 - val_loss: 3350471424.0000\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 33140404.0000 - val_loss: 3431536896.0000\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 30747380.0000 - val_loss: 3370637568.0000\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 31553556.0000 - val_loss: 3467353600.0000\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 31891928.0000 - val_loss: 3396838144.0000\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 32969202.0000 - val_loss: 3502834176.0000\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 34420728.0000 - val_loss: 3408491776.0000\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 36453320.0000 - val_loss: 3521250048.0000\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 39306968.0000 - val_loss: 3381355520.0000\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 43006468.0000 - val_loss: 3529053184.0000\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 47130316.0000 - val_loss: 3310167040.0000\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 51964736.0000 - val_loss: 3593603584.0000\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 56818344.0000 - val_loss: 3243177728.0000\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 64368748.0000 - val_loss: 3596979456.0000\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 64905516.0000 - val_loss: 3290039040.0000\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 64688656.0000 - val_loss: 3656663552.0000\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 63644600.0000 - val_loss: 3275666944.0000\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 67156424.0000 - val_loss: 3837010688.0000\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 75008552.0000 - val_loss: 3384349440.0000\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 85770536.0000 - val_loss: 3953754880.0000\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 98142592.0000 - val_loss: 3640787712.0000\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 109929936.0000 - val_loss: 4300998144.0000\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 112448928.0000 - val_loss: 3915833344.0000\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 133257176.0000 - val_loss: 5019584512.0000\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 166041312.0000 - val_loss: 4577335296.0000\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 229805536.0000 - val_loss: 6077883392.0000\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 300679392.0000 - val_loss: 7154787328.0000\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 457758528.0000 - val_loss: 11756604416.0000\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 805425920.0000 - val_loss: 9342534656.0000\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 1528388352.0000 - val_loss: 4215313152.0000\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 1588911872.0000 - val_loss: 4124566784.0000\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 606243648.0000 - val_loss: 5219820544.0000\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 180299936.0000 - val_loss: 5436987392.0000\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 84876544.0000 - val_loss: 5552116224.0000\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 50900056.0000 - val_loss: 5645448192.0000\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 36093800.0000 - val_loss: 5728175616.0000\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 27185102.0000 - val_loss: 5761149952.0000\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 22190524.0000 - val_loss: 5834224640.0000\n",
      "Epoch 41/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 18293108.0000 - val_loss: 5826843648.0000\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 16104441.0000 - val_loss: 5918497792.0000\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 14263390.0000 - val_loss: 5818932224.0000\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 13596378.0000 - val_loss: 5988871680.0000\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 13183323.0000 - val_loss: 5719392256.0000\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 13501894.0000 - val_loss: 6061255680.0000\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 14821139.0000 - val_loss: 5553035776.0000\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 15970553.0000 - val_loss: 6071501312.0000\n",
      "Epoch 49/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 18182882.0000 - val_loss: 5415583232.0000\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 18615846.0000 - val_loss: 5990631424.0000\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 20689722.0000 - val_loss: 5269210624.0000\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 21346550.0000 - val_loss: 5923968512.0000\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 21764526.0000 - val_loss: 5138546176.0000\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 21854386.0000 - val_loss: 5768805888.0000\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 19728348.0000 - val_loss: 5075159552.0000\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 19845578.0000 - val_loss: 5566251520.0000\n",
      "Epoch 57/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 23061766.0000 - val_loss: 4958346240.0000\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 31281858.0000 - val_loss: 5552122880.0000\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 34696908.0000 - val_loss: 4713965568.0000\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 37030952.0000 - val_loss: 5525679104.0000\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 38755120.0000 - val_loss: 4635163648.0000\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 34796408.0000 - val_loss: 5170450944.0000\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 32862654.0000 - val_loss: 4592381440.0000\n",
      "Epoch 64/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 26946264.0000 - val_loss: 4889982976.0000\n",
      "Epoch 65/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 23737030.0000 - val_loss: 4574325248.0000\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 34934876.0000 - val_loss: 4755194880.0000\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 42497080.0000 - val_loss: 4670588928.0000\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 60235372.0000 - val_loss: 5421858816.0000\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 138459424.0000 - val_loss: 4866825216.0000\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 319362656.0000 - val_loss: 4700510720.0000\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 190669664.0000 - val_loss: 4582937600.0000\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 95969016.0000 - val_loss: 4586169856.0000\n",
      "Epoch 73/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 45595888.0000 - val_loss: 4560730112.0000\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 37116352.0000 - val_loss: 4537241600.0000\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 33124172.0000 - val_loss: 4547891200.0000\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 38046100.0000 - val_loss: 4728698368.0000\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 44514800.0000 - val_loss: 4687303168.0000\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 51689436.0000 - val_loss: 4719213568.0000\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 64651916.0000 - val_loss: 4654676992.0000\n",
      "Epoch 80/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 84838952.0000 - val_loss: 4575605248.0000\n",
      "Epoch 81/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 132616856.0000 - val_loss: 4495830528.0000\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 248645280.0000 - val_loss: 4152422400.0000\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 356161696.0000 - val_loss: 4607421952.0000\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 337787968.0000 - val_loss: 5300066304.0000\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 260482880.0000 - val_loss: 5788408832.0000\n",
      "Epoch 86/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 154276944.0000 - val_loss: 5810203648.0000\n",
      "Epoch 87/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 100973384.0000 - val_loss: 5698226176.0000\n",
      "Epoch 88/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 81596960.0000 - val_loss: 5436603392.0000\n",
      "Epoch 89/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 82988536.0000 - val_loss: 5399225856.0000\n",
      "Epoch 90/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 97018520.0000 - val_loss: 4962577920.0000\n",
      "Epoch 91/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 121671792.0000 - val_loss: 4665990656.0000\n",
      "Epoch 92/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 157798864.0000 - val_loss: 4157769728.0000\n",
      "Epoch 93/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 198848672.0000 - val_loss: 3840909824.0000\n",
      "Epoch 94/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 238436768.0000 - val_loss: 3691397632.0000\n",
      "Epoch 95/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 259093408.0000 - val_loss: 3666747136.0000\n",
      "Epoch 96/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 263060160.0000 - val_loss: 3928987392.0000\n",
      "Epoch 97/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 238962960.0000 - val_loss: 4121880832.0000\n",
      "Epoch 98/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 240288544.0000 - val_loss: 4508601856.0000\n",
      "Epoch 99/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 282643200.0000 - val_loss: 5068285440.0000\n",
      "Epoch 100/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 391369792.0000 - val_loss: 6485933568.0000\n",
      "Epoch 101/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 390856640.0000 - val_loss: 7366112768.0000\n",
      "Epoch 102/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 331972160.0000 - val_loss: 6412620288.0000\n",
      "Epoch 103/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 186417808.0000 - val_loss: 5214115328.0000\n",
      "Epoch 104/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 99506496.0000 - val_loss: 4640376320.0000\n",
      "Epoch 105/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 76941544.0000 - val_loss: 4490846208.0000\n",
      "Epoch 106/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 61891816.0000 - val_loss: 4448321024.0000\n",
      "Epoch 107/200\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 52247180.0000 - val_loss: 4610035200.0000\n",
      "Epoch 108/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 42101664.0000 - val_loss: 4745759744.0000\n",
      "Epoch 109/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 34886832.0000 - val_loss: 4950009344.0000\n",
      "Epoch 110/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 30442872.0000 - val_loss: 5131333632.0000\n",
      "Epoch 111/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 33263048.0000 - val_loss: 5362335232.0000\n",
      "Epoch 112/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 33316030.0000 - val_loss: 5537632256.0000\n",
      "Epoch 113/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 41583240.0000 - val_loss: 5657547776.0000\n",
      "Epoch 114/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 42864340.0000 - val_loss: 5879956992.0000\n",
      "Epoch 115/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 53319828.0000 - val_loss: 5690633728.0000\n",
      "Epoch 116/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 57534852.0000 - val_loss: 6010769920.0000\n",
      "Epoch 117/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 56796312.0000 - val_loss: 5536012800.0000\n",
      "Epoch 118/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 55358532.0000 - val_loss: 5588114432.0000\n",
      "Epoch 119/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 50268700.0000 - val_loss: 5359895040.0000\n",
      "Epoch 120/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 43875184.0000 - val_loss: 5315318784.0000\n",
      "Epoch 121/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 47190756.0000 - val_loss: 5150156800.0000\n",
      "Epoch 122/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 50728380.0000 - val_loss: 4890240512.0000\n",
      "Epoch 123/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 53062800.0000 - val_loss: 4874642944.0000\n",
      "Epoch 124/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 66366272.0000 - val_loss: 4567051264.0000\n",
      "Epoch 125/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 65313880.0000 - val_loss: 4525690368.0000\n",
      "Epoch 126/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 77564896.0000 - val_loss: 4303251968.0000\n",
      "Epoch 127/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 75267384.0000 - val_loss: 4073957376.0000\n",
      "Epoch 128/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 105858696.0000 - val_loss: 4149714688.0000\n",
      "Epoch 129/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 119138392.0000 - val_loss: 3436962816.0000\n",
      "Epoch 130/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 200753872.0000 - val_loss: 3840573952.0000\n",
      "Epoch 131/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 274835424.0000 - val_loss: 3484967168.0000\n",
      "Epoch 132/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 441755008.0000 - val_loss: 4484383744.0000\n",
      "Epoch 133/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 787848064.0000 - val_loss: 4894786560.0000\n",
      "Epoch 134/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 1086853888.0000 - val_loss: 8485499392.0000\n",
      "Epoch 135/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 624617536.0000 - val_loss: 8190567936.0000\n",
      "Epoch 136/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 234102608.0000 - val_loss: 6776538624.0000\n",
      "Epoch 137/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 81205696.0000 - val_loss: 6181683712.0000\n",
      "Epoch 138/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 40168500.0000 - val_loss: 6030696448.0000\n",
      "Epoch 139/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 29034578.0000 - val_loss: 6007612416.0000\n",
      "Epoch 140/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 26554210.0000 - val_loss: 6044867584.0000\n",
      "Epoch 141/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 24764886.0000 - val_loss: 6049178112.0000\n",
      "Epoch 142/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 23222830.0000 - val_loss: 6074250752.0000\n",
      "Epoch 143/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 21452514.0000 - val_loss: 6057655808.0000\n",
      "Epoch 144/200\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 20049096.0000 - val_loss: 6053012480.0000\n",
      "Epoch 145/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 18819952.0000 - val_loss: 6024114688.0000\n",
      "Epoch 146/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 17802096.0000 - val_loss: 5968715776.0000\n",
      "Epoch 147/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 18067212.0000 - val_loss: 5955239424.0000\n",
      "Epoch 148/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 18601226.0000 - val_loss: 5825584640.0000\n",
      "Epoch 149/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 21164216.0000 - val_loss: 5912665088.0000\n",
      "Epoch 150/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 22414008.0000 - val_loss: 5548817408.0000\n",
      "Epoch 151/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 23783182.0000 - val_loss: 5804027392.0000\n",
      "Epoch 152/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 21626456.0000 - val_loss: 5355821568.0000\n",
      "Epoch 153/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 19618228.0000 - val_loss: 5644400128.0000\n",
      "Epoch 154/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 18283418.0000 - val_loss: 5339887104.0000\n",
      "Epoch 155/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 17465548.0000 - val_loss: 5538424320.0000\n",
      "Epoch 156/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 17036088.0000 - val_loss: 5275692032.0000\n",
      "Epoch 157/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 19044170.0000 - val_loss: 5546468352.0000\n",
      "Epoch 158/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 20762276.0000 - val_loss: 5165113856.0000\n",
      "Epoch 159/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 22393336.0000 - val_loss: 5436716032.0000\n",
      "Epoch 160/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 22224300.0000 - val_loss: 5053942272.0000\n",
      "Epoch 161/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 21334592.0000 - val_loss: 5311218688.0000\n",
      "Epoch 162/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 24521410.0000 - val_loss: 5136904704.0000\n",
      "Epoch 163/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 26931784.0000 - val_loss: 5086753792.0000\n",
      "Epoch 164/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 31169506.0000 - val_loss: 5347974656.0000\n",
      "Epoch 165/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 36966520.0000 - val_loss: 4903828992.0000\n",
      "Epoch 166/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 47628012.0000 - val_loss: 4803487744.0000\n",
      "Epoch 167/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 66099408.0000 - val_loss: 4612896768.0000\n",
      "Epoch 168/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 154957120.0000 - val_loss: 5395164672.0000\n",
      "Epoch 169/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 188480368.0000 - val_loss: 5247218176.0000\n",
      "Epoch 170/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 92115064.0000 - val_loss: 5178205184.0000\n",
      "Epoch 171/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 30424992.0000 - val_loss: 5154463744.0000\n",
      "Epoch 172/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 19905314.0000 - val_loss: 5302115840.0000\n",
      "Epoch 173/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 19886120.0000 - val_loss: 5463370752.0000\n",
      "Epoch 174/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 21192920.0000 - val_loss: 5595728896.0000\n",
      "Epoch 175/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 22702166.0000 - val_loss: 5495393792.0000\n",
      "Epoch 176/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 28142102.0000 - val_loss: 5754168320.0000\n",
      "Epoch 177/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 37276200.0000 - val_loss: 5363384832.0000\n",
      "Epoch 178/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 46077872.0000 - val_loss: 5955321856.0000\n",
      "Epoch 179/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 64434264.0000 - val_loss: 5675215360.0000\n",
      "Epoch 180/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 89127776.0000 - val_loss: 6574514688.0000\n",
      "Epoch 181/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 139727648.0000 - val_loss: 6734908928.0000\n",
      "Epoch 182/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 202961728.0000 - val_loss: 5696453632.0000\n",
      "Epoch 183/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 202447440.0000 - val_loss: 4864932352.0000\n",
      "Epoch 184/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 176631840.0000 - val_loss: 4238704384.0000\n",
      "Epoch 185/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 175170944.0000 - val_loss: 4029689344.0000\n",
      "Epoch 186/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 136798544.0000 - val_loss: 4100499968.0000\n",
      "Epoch 187/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 162231568.0000 - val_loss: 3929045760.0000\n",
      "Epoch 188/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 203908112.0000 - val_loss: 3771884544.0000\n",
      "Epoch 189/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 296215968.0000 - val_loss: 3734002432.0000\n",
      "Epoch 190/200\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 388698080.0000 - val_loss: 4784640000.0000\n",
      "Epoch 191/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 385805248.0000 - val_loss: 6452940800.0000\n",
      "Epoch 192/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 225738000.0000 - val_loss: 6585101312.0000\n",
      "Epoch 193/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 164034352.0000 - val_loss: 5918088192.0000\n",
      "Epoch 194/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 143030448.0000 - val_loss: 5342227968.0000\n",
      "Epoch 195/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 122816352.0000 - val_loss: 4854185984.0000\n",
      "Epoch 196/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 100603088.0000 - val_loss: 4643051520.0000\n",
      "Epoch 197/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 97811880.0000 - val_loss: 4673670656.0000\n",
      "Epoch 198/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 99596288.0000 - val_loss: 4657950720.0000\n",
      "Epoch 199/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 106902464.0000 - val_loss: 4833857536.0000\n",
      "Epoch 200/200\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 107823504.0000 - val_loss: 4974191616.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20a508f8040>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=f\"./logs_{str(datetime.datetime.now()).replace(':','_')}\")\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=200, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('test.csv')\n",
    "test_set = preprocess(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 270)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7ac31377e5752e1ed1312ad3b91e8276a597b7c31b512ba5cfdf5263aeace113"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
